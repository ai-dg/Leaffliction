# ğŸ§  Leaffliction â€” Guide personnel complet (ML Traditionnel)

> **Objectif de ce document**  
> Ce guide est un **manuel personnel de dÃ©veloppement** pour le projet **Leaffliction**.  
> Il explique l'approche **Machine Learning traditionnelle** avec extraction de features,  
> les **formules mathÃ©matiques**, et la **dÃ©fendabilitÃ© Ã  l'oral**.

---

## ğŸ“‘ Table des matiÃ¨res

1. [Vue d'ensemble du projet](#vue-densemble-du-projet)
2. [Architecture globale](#architecture-globale)
3. [ML Traditionnel vs Deep Learning](#ml-traditionnel-vs-deep-learning)
4. [Pipeline de donnÃ©es](#pipeline-de-donnÃ©es)
5. [Scripts racine (entrypoints)](#scripts-racine-entrypoints)
6. [Dossier `leaffliction/` (cÅ“ur du projet)](#dossier-leaffliction-cÅ“ur-du-projet)
7. [MathÃ©matiques et formules essentielles](#mathÃ©matiques-et-formules-essentielles)
8. [Contraintes du sujet & validation](#contraintes-du-sujet--validation)
9. [Checklist finale avant rendu](#checklist-finale-avant-rendu)
10. [Conseils pour la soutenance](#conseils-pour-la-soutenance)

---

## Vue d'ensemble du projet

**Leaffliction** est un projet de **computer vision** visant Ã  classifier des maladies de feuilles en utilisant une approche **Machine Learning traditionnelle** (SVM, Random Forest, KNN).

### Objectifs principaux

1. **Analyser** la distribution des donnÃ©es
2. **Augmenter** les donnÃ©es (images physiques sur disque)
3. **Extraire** des features numÃ©riques des images
4. **EntraÃ®ner** un modÃ¨le ML (SVM, Random Forest, KNN)
5. **PrÃ©dire** la maladie d'une feuille

### Technologies utilisÃ©es

- **scikit-learn** : modÃ¨les ML (SVM, Random Forest, KNN)
- **OpenCV** : manipulation d'images et extraction de features
- **NumPy** : calculs numÃ©riques
- **Python 3.x** : langage principal
- **Matplotlib** : visualisation

### Pipeline gÃ©nÃ©ral

```
(1) Dataset brut
     â†“
(2) Analyse distribution (Distribution.py)
     â†“
(3) Augmentations visuelles (Augmentation.py) - pour comprendre
     â†“
(4) Transformations visuelles (Transformation.py) - pour comprendre
     â†“
(5) Training (train.py)
     â”œâ”€ Split train/valid
     â”œâ”€ Augmentations (images physiques)
     â”œâ”€ Extraction features
     â”œâ”€ Normalisation (StandardScaler)
     â”œâ”€ ModÃ¨le ML (SVM/RF/KNN)
     â””â”€ Sauvegarde learnings.zip
     â†“
(6) PrÃ©diction (predict.py)
     â”œâ”€ Charge learnings.zip
     â”œâ”€ Extrait features de l'image
     â”œâ”€ PrÃ©dit la classe
     â””â”€ (Optionnel) Affiche transformations
```

---

## Architecture globale

```
.
â”œâ”€â”€ Distribution.py          # Partie 1: Analyse distribution
â”œâ”€â”€ Augmentation.py          # Partie 2: Visualisation augmentations
â”œâ”€â”€ Transformation.py        # Partie 3: Visualisation transformations
â”œâ”€â”€ train.py                 # Partie 4: EntraÃ®nement ML
â”œâ”€â”€ predict.py               # Partie 4: PrÃ©diction ML
â”œâ”€â”€ signature.txt            # SHA1 du learnings.zip
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ GUIDE.md                              # Guide complet ML
â”‚   â”œâ”€â”€ GUIDE_IMPLEMENTATION.md               # Guide d'implÃ©mentation
â”‚   â”œâ”€â”€ ETAT_PROJET.md                        # Ã‰tat du projet
â”‚   â”œâ”€â”€ ARCHITECTURE_ML_TRADITIONNELLE.md     # Architecture ML
â”‚   â””â”€â”€ en.subject.pdf                        # Sujet original
â”‚
â””â”€â”€ leaffliction/            # Package principal
    â”œâ”€â”€ cli.py              # âœ… FinalisÃ© - Parsers argparse
    â”œâ”€â”€ utils.py            # âœ… FinalisÃ© - Utilitaires (paths, zip, hash)
    â”œâ”€â”€ plotting.py         # âœ… FinalisÃ© - Visualisations
    â”œâ”€â”€ dataset.py          # ğŸ”„ En cours - Scanner, Splitter
    â”œâ”€â”€ augmentations.py    # ğŸ“ Squelette - Augmentations (NumPy/OpenCV)
    â”œâ”€â”€ transformations.py  # ğŸ“ Squelette - Transformations + FeatureExtractor â­
    â”œâ”€â”€ model.py            # ğŸ“ Squelette - MLModelFactory, MLModelBundle
    â”œâ”€â”€ train_pipeline.py   # ğŸ“ Squelette - MLTrainer
    â””â”€â”€ predict_pipeline.py # ğŸ“ Squelette - MLPredictor
```

---

## ML Traditionnel vs Deep Learning

### Comparaison

| Aspect | Deep Learning (CNN) | ML Traditionnel |
|--------|-------------------|-----------------|
| **ModÃ¨le** | RÃ©seau de neurones | SVM, Random Forest, KNN |
| **Features** | Apprises automatiquement | Extraites manuellement |
| **DonnÃ©es** | Beaucoup (milliers) | Moins (centaines) |
| **Training** | Lent (GPU, heures) | Rapide (CPU, minutes) |
| **InterprÃ©tabilitÃ©** | Faible | Ã‰levÃ©e |
| **ComplexitÃ©** | Haute | Moyenne |

### Pipeline Visuel

**Deep Learning** :
```
Image â†’ CNN â†’ PrÃ©diction
```

**ML Traditionnel** :
```
Image â†’ Extraction Features â†’ ModÃ¨le ML â†’ PrÃ©diction
       (Histogrammes, textures, contours)
```

### Pourquoi ML Traditionnel ?

**Avantages** :
- âœ… Plus simple Ã  comprendre et expliquer
- âœ… Plus rapide Ã  entraÃ®ner (minutes vs heures)
- âœ… Pas besoin de GPU
- âœ… Features interprÃ©tables (on sait ce qu'on mesure)
- âœ… Bon pour la soutenance (facile Ã  justifier)

**InconvÃ©nients** :
- âš ï¸ Accuracy potentiellement plus faible que CNN
- âš ï¸ NÃ©cessite une bonne extraction de features
- âš ï¸ Moins flexible pour des images trÃ¨s complexes

---

## Pipeline de donnÃ©es

### SchÃ©ma dÃ©taillÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING (train.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. DatasetScanner.scan()
   â””â”€ Lit leaves/images/
      â””â”€ Retourne DatasetIndex (class_names, items, counts)

2. DatasetSplitter.split()
   â””â”€ Split stratifiÃ© train/valid (80/20)
      â””â”€ Retourne (train_items, valid_items)

3. AugmentationEngine.augment_dataset() [OPTIONNEL]
   â””â”€ CrÃ©e des images augmentÃ©es PHYSIQUES
      â””â”€ Sauvegarde dans artifacts/augmented/
      â””â”€ Retourne liste Ã©tendue (originales + augmentÃ©es)

4. FeatureExtractor.extract_batch(train_items)
   â””â”€ Extrait features de toutes les images train
      â””â”€ Retourne X_train (n_train, 824), y_train (n_train,)

5. FeatureExtractor.extract_batch(valid_items)
   â””â”€ Extrait features de toutes les images valid
      â””â”€ Retourne X_valid (n_valid, 824), y_valid (n_valid,)

6. StandardScaler
   â””â”€ fit_transform(X_train) â†’ X_train_scaled
   â””â”€ transform(X_valid) â†’ X_valid_scaled

7. MLModelFactory.build(model_type="svm")
   â””â”€ Construit modÃ¨le sklearn (SVM/RF/KNN)

8. model.fit(X_train_scaled, y_train)
   â””â”€ EntraÃ®nement

9. model.score(X_valid_scaled, y_valid)
   â””â”€ Accuracy validation > 90% âœ…

10. MLModelBundle.save()
    â””â”€ Sauvegarde model.pkl + scaler.pkl + labels.json

11. TrainingPackager.build_zip()
    â””â”€ CrÃ©e learnings.zip


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRÃ‰DICTION (predict.py)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. MLModelBundle.load_from_zip()
   â””â”€ Extrait et charge model.pkl, scaler.pkl, labels.json

2. FeatureExtractor.extract_features(image_path)
   â””â”€ Extrait features de l'image (824,)

3. scaler.transform(features)
   â””â”€ Normalise les features

4. model.predict(features_scaled)
   â””â”€ PrÃ©diction

5. model.predict_proba(features_scaled)
   â””â”€ ProbabilitÃ©s

6. LabelEncoder.decode(class_id)
   â””â”€ Convertit ID â†’ nom classe

7. (Optionnel) TransformationEngine.apply_all()
   â””â”€ Visualisation transformations
```

---

## Scripts racine (entrypoints)

### RÃ¨gle fondamentale

> **Aucune logique mÃ©tier dans les scripts racine.**  
> Ils doivent uniquement :
> 1. Parser les arguments (via `cli.py`)
> 2. Instancier des classes (depuis `leaffliction/`)
> 3. Appeler des mÃ©thodes

---

### `Distribution.py` âœ…

**But** : Analyser la rÃ©partition des donnÃ©es (Partie 1 du sujet)

**Pipeline** :
```python
1. Parser arguments (dataset_dir)
2. DatasetScanner.scan(dataset_dir)
3. DistributionPlotter.plot_pie() + plot_bar()
```

**Utilisation** :
```bash
python Distribution.py ./leaves/images/
```

**Pourquoi c'est important ?**
- DÃ©tection de dÃ©sÃ©quilibre de classes
- Justification des augmentations
- ComprÃ©hension du dataset

---

### `Augmentation.py` âœ…

**But** : Visualiser les 6 augmentations sur UNE image (Partie 2 du sujet)

**Pipeline** :
```python
1. Parser arguments (image_path)
2. Charger l'image avec OpenCV
3. Convertir BGR â†’ RGB
4. AugmentationEngine.default_six()
5. engine.apply_all(img)
6. GridPlotter.show_grid()
7. AugmentationSaver.save_all()
```

**Utilisation** :
```bash
python Augmentation.py "./leaves/images/Apple_healthy/image (1).JPG"
```

**RÃ©sultat** : 6 images sauvegardÃ©es avec suffixes
- `image (1)_FlipH.JPG`
- `image (1)_FlipV.JPG`
- `image (1)_Rotate.JPG`
- `image (1)_BrightContrast.JPG`
- `image (1)_Blur.JPG`
- `image (1)_CropResize.JPG`

---

### `Transformation.py` âœ…

**But** : Visualiser les 6 transformations sur UNE image (Partie 3 du sujet)

**Pipeline** :
```python
1. Parser arguments (image_path ou -src/-dst)
2. TransformationEngine.default_six()
3. Mode single: 
   - Charger image avec OpenCV
   - engine.apply_all() 
   - GridPlotter.show_grid()
4. Mode batch: 
   - BatchTransformer.run()
```

**Utilisation** :
```bash
# Mode single
python Transformation.py "./leaves/images/Apple_healthy/image (1).JPG"

# Mode batch
python Transformation.py -src ./leaves/images/ -dst ./transformed/
```

**Transformations** :
- Grayscale
- Canny (contours)
- Histogram Equalisation
- Sharpen
- Threshold
- Morphology

---

### `train.py` âœ…

**But** : EntraÃ®ner le modÃ¨le ML (Partie 4 du sujet)

**Pipeline** :
```python
1. Parser arguments
2. Scanner dataset
3. Split train/valid (stratifiÃ©)
4. (Optionnel) Augmenter train set (images physiques)
5. Extraire features (train + valid)
6. Normaliser features (StandardScaler)
7. Construire modÃ¨le ML (SVM/RF/KNN)
8. EntraÃ®ner
9. Ã‰valuer (accuracy > 90%)
10. Sauvegarder bundle (model.pkl, scaler.pkl, labels.json)
11. CrÃ©er learnings.zip
12. GÃ©nÃ©rer signature.txt
```

**Utilisation** :
```bash
python train.py ./leaves/images/ --model_type svm --augment
```

**Options** :
- `--model_type` : svm, random_forest, knn (dÃ©faut: svm)
- `--augment` : Activer augmentations (dÃ©faut: True)
- `--aug_per_image` : Nombre d'augmentations par image (dÃ©faut: 3)
- `--valid_ratio` : Ratio de validation (dÃ©faut: 0.2)
- `--seed` : Seed pour reproductibilitÃ© (dÃ©faut: 42)

**Contraintes** :
- âœ… Valid accuracy > 90%
- âœ… Valid count â‰¥ 100 images
- âœ… Sauvegarder tout dans learnings.zip

---

### `predict.py` âœ…

**But** : PrÃ©dire la classe d'une image (Partie 4 du sujet)

**Pipeline** :
```python
1. Parser arguments (bundle_zip, image_path)
2. Charger MLModelBundle
3. Extraire features de l'image
4. Normaliser features
5. PrÃ©dire avec le modÃ¨le ML
6. Afficher rÃ©sultat + top K prÃ©dictions
7. (Optionnel) Afficher transformations
```

**Utilisation** :
```bash
python predict.py learnings.zip "./leaves/images/Apple_Black_rot/image (1).JPG"
```

**Sortie** :
```
ğŸ” Predicting disease for: image (1).JPG
ğŸ“¦ Using model from: learnings.zip

============================================================
âœ… PREDICTION RESULT
============================================================
ğŸƒ Predicted class: Apple_Black_rot
ğŸ“Š Confidence: 95.7%

Top 3 predictions:
   1. Apple_Black_rot: 95.7%
   2. Apple_scab: 3.2%
   3. Grape_Black_rot: 1.1%

============================================================
```

---

## Dossier `leaffliction/` (cÅ“ur du projet)

### `cli.py` âœ… FinalisÃ©

**ResponsabilitÃ©s** :
- Centralisation de tous les parsers `argparse`
- `build_distribution_parser()`
- `build_augmentation_parser()`
- `build_transformation_parser()`
- `build_train_parser()`
- `build_predict_parser()`

---

### `utils.py` âœ… FinalisÃ©

**ResponsabilitÃ©s** :
- `PathManager`: gestion chemins, itÃ©ration images
- `ZipPackager`: crÃ©ation/extraction zip
- `Hasher`: calcul SHA1

---

### `plotting.py` âœ… FinalisÃ©

**ResponsabilitÃ©s** :
- `DistributionPlotter`: pie chart + bar chart
- `GridPlotter`: grilles d'images (augmentations/transformations)

---

### `dataset.py` ğŸ”„ En cours

**Classes** :

#### `DatasetIndex`
```python
@dataclass
class DatasetIndex:
    root: Path
    class_names: List[str]  # TriÃ©s alphabÃ©tiquement
    items: List[Tuple[Path, int]]  # (chemin, class_id)
    counts: Dict[str, int]  # {class_name: count}
```

#### `DatasetScanner`
```python
def scan(self, root: Path) -> DatasetIndex:
    """
    Scan rÃ©cursif du dossier:
    root/
      Apple_healthy/
        image1.jpg
      Apple_scab/
        image2.jpg
    
    Retourne: DatasetIndex
    """
```

#### `DatasetSplitter` âœ… ImplÃ©mentÃ©
```python
def split(
    self,
    items: List[Tuple[Path, int]],
    valid_ratio: float,
    seed: int,
    stratified: bool = True
) -> Tuple[List, List]:
    """
    Split stratifiÃ© pour conserver proportions de classes.
    """
```

---

### `augmentations.py` ğŸ“ Squelette

**DiffÃ©rence clÃ© avec CNN** :
- CNN : Augmentations Ã  la volÃ©e pendant training
- ML : Augmentations crÃ©ent des images PHYSIQUES sur disque

**Classes d'augmentation** (NumPy/OpenCV) :
- `FlipHorizontalAug` : `cv2.flip(img, 1)`
- `FlipVerticalAug` : `cv2.flip(img, 0)`
- `RotateAug` : `cv2.warpAffine()`
- `BrightnessContrastAug` : Ajustement pixel values
- `GaussianBlurAug` : `cv2.GaussianBlur()`
- `RandomCropResizeAug` : Crop + `cv2.resize()`

**Moteur** :
```python
class AugmentationEngine:
    def default_six(cls) -> "AugmentationEngine":
        """Factory des 6 augmentations"""
    
    def apply_all(self, img) -> Dict[str, np.ndarray]:
        """Pour visualisation (Augmentation.py)"""
    
    def apply_random(self, img, n=2) -> np.ndarray:
        """Applique n augmentations alÃ©atoires"""
    
    def augment_dataset(self, train_items, output_dir, n=3):
        """
        CrÃ©e images augmentÃ©es PHYSIQUES (pour training)
        
        Input:  400 images
        Output: 400 + 1200 = 1600 images (sauvegardÃ©es sur disque)
        """
```

---

### `transformations.py` ğŸ“ Squelette â­

**RÃ´le dans ML Traditionnel** :
- Transformations = Extraction de Features
- Essentielles pour le modÃ¨le ML

**Classes de transformation** (NumPy/OpenCV) :
- `GrayscaleTf` : `cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)`
- `CannyEdgesTf` : `cv2.Canny()`
- `HistogramEqualisationTf` : `cv2.equalizeHist()`
- `SharpenTf` : Convolution avec kernel
- `ThresholdTf` : Seuillage binaire
- `MorphologyTf` : `cv2.erode()`, `cv2.dilate()`

**Moteur** :
```python
class TransformationEngine:
    def default_six(cls) -> "TransformationEngine":
        """Factory des 6 transformations"""
    
    def apply_all(self, img) -> Dict[str, np.ndarray]:
        """Applique toutes les transformations"""
```

**FeatureExtractor** â­ **CLASSE CENTRALE** :
```python
class FeatureExtractor:
    def extract_features(self, img_path: Path) -> np.ndarray:
        """
        Extrait ~800-1000 features numÃ©riques depuis une image
        
        Features extraites:
        1. Histogrammes RGB : 256 bins Ã— 3 = 768 features
        2. Statistiques RGB : mean, std, min, max Ã— 3 = 12 features
        3. Stats des transformations : 4 stats Ã— 6 = 24 features
        4. (Optionnel) Textures Haralick : 13 features
        5. (Optionnel) Moments de Hu : 7 features
        
        Returns:
            np.ndarray de shape (n_features,)  # ~824 features
        """
    
    def extract_batch(self, items) -> Tuple[np.ndarray, np.ndarray]:
        """
        Extrait features de plusieurs images
        
        Returns:
            X: np.ndarray de shape (n_samples, n_features)
            y: np.ndarray de shape (n_samples,)
        """
```

---

### `model.py` ğŸ“ Squelette

**Classes** :

#### `LabelEncoder`
```python
def fit(self, class_names: List[str]):
    """CrÃ©e mapping class_name â†” id"""

def encode(self, class_name: str) -> int:
    """class_name â†’ id"""

def decode(self, class_id: int) -> str:
    """id â†’ class_name"""

def to_json_dict() -> Dict:
    """Pour sauvegarde"""

@classmethod
def from_json_dict(cls, data: Dict) -> "LabelEncoder":
    """Pour chargement"""
```

#### `MLModelFactory`
```python
def build(self, cfg: ModelConfig, model_type: str = "svm"):
    """
    Construit un modÃ¨le sklearn:
    
    - "svm": SVC(kernel='rbf', C=1.0, probability=True)
    - "random_forest": RandomForestClassifier(n_estimators=100)
    - "knn": KNeighborsClassifier(n_neighbors=5)
    """
```

#### `MLModelBundle`
```python
def save(self, out_dir: Path):
    """
    Sauvegarde:
    - model.pkl (modÃ¨le sklearn)
    - scaler.pkl (StandardScaler)
    - labels.json
    - config.json
    - feature_config.json
    """

@classmethod
def load_from_zip(cls, zip_path: Path):
    """Charge depuis learnings.zip"""

def predict(self, features: np.ndarray):
    """
    PrÃ©dit la classe
    
    Returns:
        pred_id: int
        probs: Dict[str, float]
    """
```

---

### `train_pipeline.py` ğŸ“ Squelette

**Classes** :

#### `MLTrainer`
```python
def train(self, dataset_dir, out_dir, cfg) -> Metrics:
    """
    Pipeline complet ML:
    1. Scanner dataset
    2. Split train/valid (stratifiÃ©)
    3. (Optionnel) Augmenter train set (images physiques)
    4. Extraire features (train + valid)
    5. Normaliser features (StandardScaler)
    6. EntraÃ®ner modÃ¨le ML (SVM/RF/KNN)
    7. Ã‰valuer (accuracy > 90%)
    8. Sauvegarder bundle
    """
```

#### `RequirementsGate`
```python
def assert_ok(self, metrics: Metrics):
    """
    VÃ©rifie:
    - valid_accuracy > 0.90
    - valid_count >= 100
    
    LÃ¨ve ValueError si non conforme
    """
```

#### `TrainingPackager`
```python
def build_zip(self, artifacts_dir, out_zip):
    """CrÃ©e learnings.zip"""
```

---

### `predict_pipeline.py` ğŸ“ Squelette

**Classes** :

#### `MLPredictor`
```python
def predict(self, bundle_zip, image_path, cfg):
    """
    1. Charge bundle (model.pkl, scaler.pkl)
    2. Extrait features de l'image
    3. Normalise features
    4. PrÃ©dit avec modÃ¨le ML
    5. Retourne (label, probs, transformed)
    """
```

#### `PredictionVisualiser`
```python
def show(self, original, transformed, predicted_label):
    """Affiche grille avec rÃ©sultat"""
```

---

## MathÃ©matiques et formules essentielles

### ğŸ”¹ StandardScaler (Normalisation)

**Formule** :
```
x_scaled = (x - mean) / std
```

**Pourquoi** : Met toutes les features sur la mÃªme Ã©chelle (mean=0, std=1)

**Exemple** :
```
Feature 1: [100, 200, 300] â†’ mean=200, std=81.6
Feature 2: [0.1, 0.2, 0.3] â†’ mean=0.2, std=0.08

AprÃ¨s normalisation:
Feature 1: [-1.22, 0, 1.22]
Feature 2: [-1.22, 0, 1.22]

â†’ MÃªme Ã©chelle !
```

---

### ğŸ”¹ SVM (Support Vector Machine)

**Objectif** : Trouver l'hyperplan qui sÃ©pare au mieux les classes

**Formule du kernel RBF** :
```
K(x, x') = exp(-Î³ ||x - x'||Â²)
```

OÃ¹ :
- Î³ = gamma (contrÃ´le la "portÃ©e" du kernel)
- ||x - x'|| = distance euclidienne

**DÃ©cision** :
```
f(x) = sign(Î£ Î±áµ¢ yáµ¢ K(xáµ¢, x) + b)
```

---

### ğŸ”¹ Random Forest

**Principe** : Ensemble d'arbres de dÃ©cision

**PrÃ©diction** :
```
Å· = mode{treeâ‚(x), treeâ‚‚(x), ..., tree_n(x)}
```

**ProbabilitÃ©** :
```
P(classe_k | x) = (nombre d'arbres prÃ©disant k) / n_arbres
```

---

### ğŸ”¹ KNN (K-Nearest Neighbors)

**Principe** : Voter parmi les K voisins les plus proches

**Distance euclidienne** :
```
d(x, x') = âˆš(Î£áµ¢ (xáµ¢ - x'áµ¢)Â²)
```

**PrÃ©diction** :
```
Å· = mode{yâ‚, yâ‚‚, ..., y_k}
```

---

### ğŸ”¹ Accuracy

```
Accuracy = (Nombre de prÃ©dictions correctes) / (Nombre total)
```

**Contrainte du sujet** : Accuracy > 90%

---

### ğŸ”¹ Histogramme

**Formule** :
```
hist[i] = nombre de pixels avec valeur dans [i, i+1)
hist_normalized[i] = hist[i] / Î£ hist[j]
```

---

## Contraintes du sujet & validation

### âœ… Contraintes obligatoires

1. **Accuracy validation > 90%**
   - VÃ©rifiÃ©e par `RequirementsGate`
   - Minimum 100 images de validation

2. **Dataset interdit dans le repo**
   - Seulement `signature.txt` (SHA1 du zip)
   - VÃ©rification pendant la dÃ©fense

3. **Structure du zip**
   ```
   learnings.zip/
     model.pkl              # ModÃ¨le sklearn
     scaler.pkl             # StandardScaler
     labels.json            # Mapping classes
     config.json            # Configuration
     feature_config.json    # Config features
   ```

4. **Signature SHA1**
   ```bash
   sha1sum learnings.zip > signature.txt
   ```

---

## Checklist finale avant rendu

### Code

- [ ] Tous les scripts racine fonctionnels
- [ ] Code modulaire et propre
- [ ] Pas de code mort
- [ ] Imports corrects
- [ ] Type hints prÃ©sents

### Dataset

- [ ] Dataset **NON** dans le repo
- [ ] `signature.txt` prÃ©sent
- [ ] SHA1 correct

### Training

- [ ] Accuracy > 90% sur validation
- [ ] â‰¥ 100 images de validation
- [ ] `learnings.zip` reproductible

### Documentation

- [ ] README.md Ã  jour
- [ ] GUIDE.md complet
- [ ] Commentaires dans le code

---

## Conseils pour la soutenance

### 1. Expliquer l'architecture ML

**Soyez capable de dessiner au tableau** :
```
Dataset â†’ Scanner â†’ Split â†’ Augment (images physiques)
                                â†“
                        Extract Features
                                â†“
                        Normalize (StandardScaler)
                                â†“
                        Train ML Model (SVM/RF/KNN)
                                â†“
                        Validation (accuracy > 90%)
```

### 2. Justifier le choix ML traditionnel

**Points forts** :
- âœ… Plus simple Ã  comprendre et expliquer
- âœ… Plus rapide Ã  entraÃ®ner (minutes vs heures)
- âœ… Pas besoin de GPU
- âœ… Features interprÃ©tables
- âœ… Bon pour la soutenance

**Quand utiliser CNN** :
- Dataset trÃ¨s large (>10k images)
- Images trÃ¨s complexes
- Besoin d'accuracy maximale

### 3. Expliquer l'extraction de features

**ÃŠtre capable d'expliquer** :
- Histogrammes RGB : Distribution des couleurs
- Statistiques : CaractÃ©ristiques globales
- Transformations : Contours, textures, formes
- Total : ~800-1000 features par image

### 4. MaÃ®triser les formules

**ÃŠtre capable d'expliquer** :
- StandardScaler : Normalisation des features
- SVM : SÃ©paration par hyperplan
- Random Forest : Vote d'arbres
- KNN : Vote des voisins

### 5. DÃ©montrer la reproductibilitÃ©

**Montrer** :
```bash
# 1. Training
python train.py leaves/images/ --model_type svm

# 2. VÃ©rification SHA1
sha1sum learnings.zip
cat signature.txt

# 3. PrÃ©diction
python predict.py learnings.zip test_image.jpg
```

### 6. Anticiper les questions

**Questions frÃ©quentes** :
- "Pourquoi ML traditionnel et pas CNN ?"
  â†’ Plus simple, plus rapide, features interprÃ©tables
  
- "Comment extrayez-vous les features ?"
  â†’ Histogrammes, stats, transformations (dÃ©tailler)
  
- "Quelle est votre accuracy finale ?"
  â†’ Montrer les rÃ©sultats (>90%)
  
- "Combien de temps pour entraÃ®ner ?"
  â†’ Quelques minutes (vs heures pour CNN)
  
- "Pourquoi SVM plutÃ´t que Random Forest ?"
  â†’
