# ğŸƒ Leaffliction â€” Guide Complet (ML Traditionnel)

> **Objectif de ce document**  
> Ce guide est un **manuel personnel de dÃ©veloppement** pour le projet **Leaffliction**.  
> Il explique l'approche **Machine Learning traditionnelle** avec extraction de features,  
> les **formules mathÃ©matiques**, et la **dÃ©fendabilitÃ© Ã  l'oral**.

---

## ğŸ“‘ Table des matiÃ¨res

1. [Vue d'ensemble du projet](#vue-densemble-du-projet)
2. [Architecture globale](#architecture-globale)
3. [ML Traditionnel vs Deep Learning](#ml-traditionnel-vs-deep-learning)
4. [Partie 1 : Analyse du Dataset](#partie-1--analyse-du-dataset)
5. [Partie 2 : Augmentation de donnÃ©es](#partie-2--augmentation-de-donnÃ©es)
6. [Partie 3 : Transformations et Features](#partie-3--transformations-et-features)
7. [Partie 4 : Classification ML](#partie-4--classification-ml)
8. [Module leaffliction/](#module-leaffliction)
9. [Pipeline ML Traditionnel dÃ©taillÃ©](#pipeline-ml-traditionnel-dÃ©taillÃ©)
10. [MathÃ©matiques et formules](#mathÃ©matiques-et-formules)
11. [Contraintes du sujet](#contraintes-du-sujet)
12. [GÃ©nÃ©ration de signature.txt](#gÃ©nÃ©ration-de-signaturetxt)
13. [Checklist finale](#checklist-finale)
14. [Conseils pour la soutenance](#conseils-pour-la-soutenance)

---

<a id="vue-densemble-du-projet"></a>
## 1. Vue d'ensemble du projet

**Leaffliction** est un projet de **computer vision** visant Ã  classifier des maladies de feuilles Ã  partir d'images en utilisant une approche **Machine Learning traditionnelle**.

### Objectifs principaux

1. **Analyser** la distribution des donnÃ©es
2. **Augmenter** les donnÃ©es (images physiques sur disque)
3. **Extraire** des features numÃ©riques des images
4. **EntraÃ®ner** un modÃ¨le ML (SVM, Random Forest, KNN)
5. **PrÃ©dire** la maladie d'une feuille

### Technologies utilisÃ©es

- **scikit-learn** : modÃ¨les ML (SVM, Random Forest, KNN)
- **OpenCV** : manipulation d'images et extraction de features
- **NumPy** : calculs numÃ©riques
- **Python 3.x** : langage principal
- **Matplotlib** : visualisation

---

<a id="architecture-globale"></a>
## 2. Architecture globale

```
Leaffliction/
â”‚
â”œâ”€â”€ Distribution.py          # Partie 1: Analyse distribution
â”œâ”€â”€ Augmentation.py          # Partie 2: Visualisation augmentations
â”œâ”€â”€ Transformation.py        # Partie 3: Visualisation transformations
â”œâ”€â”€ train.py                 # Partie 4: EntraÃ®nement modÃ¨le ML
â”œâ”€â”€ predict.py               # Partie 4: PrÃ©diction
â”œâ”€â”€ signature.txt            # Hash SHA1 du learnings.zip
â”œâ”€â”€ README.md
â”‚
â””â”€â”€ leaffliction/            # Package Python
    â”œâ”€â”€ cli.py               # âœ… Parsers argparse
    â”œâ”€â”€ utils.py             # âœ… PathManager, Hasher, ZipPackager
    â”œâ”€â”€ plotting.py          # âœ… Visualisations
    â”œâ”€â”€ dataset.py           # Scanner, Splitter
    â”œâ”€â”€ augmentations.py     # Augmentations (images physiques)
    â”œâ”€â”€ transformations.py   # Transformations + FeatureExtractor â­
    â”œâ”€â”€ model.py             # MLModelFactory, MLModelBundle
    â”œâ”€â”€ train_pipeline.py    # MLTrainer
    â””â”€â”€ predict_pipeline.py  # MLPredictor
```

### Principe de sÃ©paration

**Scripts racine** : Parsing + Instanciation + Appel
**Package leaffliction/** : Toute la logique mÃ©tier

---

<a id="ml-traditionnel-vs-deep-learning"></a>
## 3. ML Traditionnel vs Deep Learning

### Comparaison

| Aspect | Deep Learning (CNN) | ML Traditionnel |
|--------|-------------------|-----------------|
| **ModÃ¨le** | RÃ©seau de neurones | SVM, Random Forest, KNN |
| **Features** | Apprises automatiquement | Extraites manuellement |
| **DonnÃ©es** | Beaucoup (milliers) | Moins (centaines) |
| **Training** | Lent (GPU, heures) | Rapide (CPU, minutes) |
| **InterprÃ©tabilitÃ©** | Faible | Ã‰levÃ©e |
| **ComplexitÃ©** | Haute | Moyenne |

### Pipeline Visuel

**Deep Learning** :
```
Image â†’ CNN â†’ PrÃ©diction
```

**ML Traditionnel** :
```
Image â†’ Extraction Features â†’ ModÃ¨le ML â†’ PrÃ©diction
       (Histogrammes, textures, contours)
```

### Pourquoi ML Traditionnel ?

**Avantages** :
- âœ… Plus simple Ã  comprendre et expliquer
- âœ… Plus rapide Ã  entraÃ®ner (minutes vs heures)
- âœ… Pas besoin de GPU
- âœ… Features interprÃ©tables (on sait ce qu'on mesure)
- âœ… Bon pour la soutenance (facile Ã  justifier)

**InconvÃ©nients** :
- âš ï¸ Accuracy potentiellement plus faible que CNN
- âš ï¸ NÃ©cessite une bonne extraction de features
- âš ï¸ Moins flexible pour des images trÃ¨s complexes

---

<a id="partie-1--analyse-du-dataset"></a>
## 4. Partie 1 : Analyse du Dataset

### Objectif

Analyser la distribution des classes dans le dataset pour dÃ©tecter les dÃ©sÃ©quilibres.

### Utilisation

```bash
python Distribution.py ./leaves/images/
```

### ImplÃ©mentation

```python
# Distribution.py
from pathlib import Path
from leaffliction.cli import CLIBuilder
from leaffliction.dataset import DatasetScanner
from leaffliction.plotting import DistributionPlotter

def main() -> None:
    parser = CLIBuilder().build_distribution_parser()
    args = parser.parse_args()
    
    dataset_dir = Path(args.dataset_dir)
    
    # Scanner le dataset
    scanner = DatasetScanner()
    index = scanner.scan(dataset_dir)
    
    # Afficher les graphiques
    title = f"Dataset distribution: {index.root.name}"
    plotter = DistributionPlotter()
    plotter.plot_pie(index.counts, title=title)
    plotter.plot_bar(index.counts, title=title)
```

### Sortie attendue

- **Pie chart** : Proportions de chaque classe
- **Bar chart** : Nombre d'images par classe

### Pourquoi c'est important

- DÃ©tection du dÃ©sÃ©quilibre de classes
- Justification des augmentations
- ComprÃ©hension du dataset

---

<a id="partie-2--augmentation-de-donnÃ©es"></a>
## 5. Partie 2 : Augmentation de donnÃ©es

### Objectif

CrÃ©er des **images physiques augmentÃ©es** sur disque pour Ã©quilibrer le dataset.

### DiffÃ©rence avec Deep Learning

**Deep Learning** : Augmentations Ã  la volÃ©e pendant le training (dans le pipeline)
**ML Traditionnel** : Augmentations crÃ©ent des fichiers AVANT le training

### Les 6 Augmentations

| Augmentation | Description | ParamÃ¨tre |
|-------------|-------------|-----------|
| **FlipH** | Miroir horizontal | - |
| **FlipV** | Miroir vertical | - |
| **Rotate** | Rotation | angle=15Â° |
| **Brightness** | LuminositÃ© | factor=20 |
| **Blur** | Flou gaussien | sigma=1.5 |
| **Crop** | Recadrage + resize | ratio=0.85 |

### Utilisation (Visualisation)

```bash
python Augmentation.py "./leaves/images/Apple_healthy/image (1).JPG"
```

**Sortie** :
- Affichage grille (original + 6 augmentations)
- Sauvegarde 6 fichiers avec suffixes

### Utilisation (Training)

Dans `train.py`, les augmentations sont appliquÃ©es automatiquement :

```python
# Augmenter le train set
if cfg.augment_train:
    aug_engine = AugmentationEngine.default_six()
    train_items = aug_engine.augment_dataset(
        train_items,
        out_dir / "augmented",
        augmentations_per_image=3  # 3 versions par image
    )
```

**RÃ©sultat** :
- 400 images originales â†’ 400 + 1200 augmentÃ©es = 1600 images
- Toutes sauvegardÃ©es sur disque dans `augmented/`

---

<a id="partie-3--transformations-et-features"></a>
## 6. Partie 3 : Transformations et Features

### RÃ´le dans ML Traditionnel

**Transformations** = **Extraction de Features**

Les transformations ne sont plus juste pour la visualisation, elles sont **essentielles** pour extraire des caractÃ©ristiques numÃ©riques.

### Les 6 Transformations

| Transformation | Description | Features extraites |
|---------------|-------------|-------------------|
| **Grayscale** | Niveaux de gris | Histogramme, stats |
| **Canny** | DÃ©tection contours | Nombre, densitÃ© |
| **HistEq** | Ã‰galisation histogramme | Contraste amÃ©liorÃ© |
| **Sharpen** | Accentuation | DÃ©tails renforcÃ©s |
| **Threshold** | Seuillage binaire | Segmentation |
| **Morphology** | Ã‰rosion/dilatation | Formes nettoyÃ©es |

### Extraction de Features

**FeatureExtractor** extrait ~800-1000 features numÃ©riques par image :

1. **Histogrammes RGB** : 256 bins Ã— 3 channels = 768 features
2. **Statistiques RGB** : mean, std, min, max Ã— 3 = 12 features
3. **Stats des transformations** : 4 stats Ã— 6 = 24 features
4. **Textures** (optionnel) : Haralick = 13 features
5. **Formes** (optionnel) : Moments de Hu = 7 features

**Total** : ~800-1000 features par image

### Exemple de Features

```
Image: Apple_healthy/image1.jpg

Features extraites:
[
  # Histogramme R
  0.012, 0.015, 0.018, ..., 0.003,  # 256 valeurs
  
  # Histogramme G
  0.010, 0.013, 0.020, ..., 0.005,  # 256 valeurs
  
  # Histogramme B
  0.008, 0.011, 0.016, ..., 0.004,  # 256 valeurs
  
  # Stats RGB
  120.5, 45.2, 0, 255,  # R: mean, std, min, max
  115.3, 42.1, 0, 255,  # G: mean, std, min, max
  110.8, 40.5, 0, 255,  # B: mean, std, min, max
  
  # Stats Grayscale
  115.2, 43.5, 0, 255,
  
  # Stats Canny
  0.15, 0.08, 0, 1,
  
  # ... autres transformations
]

â†’ Vecteur de 824 features
```

### Utilisation (Visualisation)

```bash
python Transformation.py "./leaves/images/Apple_healthy/image (1).JPG"
```

### Utilisation (Training)

```python
# Extraire features
feature_extractor = FeatureExtractor(
    TransformationEngine.default_six().tfs
)

X_train, y_train = feature_extractor.extract_batch(train_items)
# X_train shape: (n_images, 824)
# y_train shape: (n_images,)
```

---

<a id="partie-4--classification-ml"></a>
## 7. Partie 4 : Classification ML

### Pipeline Complet

```
1. Scanner dataset
2. Split train/valid (80/20, stratifiÃ©)
3. Augmenter train set (images physiques)
4. Extraire features (train + valid)
5. Normaliser features (StandardScaler)
6. EntraÃ®ner modÃ¨le ML (SVM/Random Forest/KNN)
7. Ã‰valuer (accuracy > 90%)
8. Sauvegarder (model.pkl, scaler.pkl, labels.json)
9. Zipper (learnings.zip)
```

### ModÃ¨les Disponibles

#### **SVM (Support Vector Machine)**
```python
from sklearn.svm import SVC

model = SVC(
    kernel='rbf',        # Radial Basis Function
    C=1.0,               # RÃ©gularisation
    gamma='scale',
    probability=True,    # Pour avoir des probabilitÃ©s
    random_state=42
)
```

**Avantages** : Performant, robuste
**InconvÃ©nients** : Lent sur gros datasets

#### **Random Forest**
```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=100,    # 100 arbres
    max_depth=None,
    random_state=42,
    n_jobs=-1            # Tous les CPU
)
```

**Avantages** : Rapide, robuste, interprÃ©table
**InconvÃ©nients** : Peut overfitter

#### **KNN (K-Nearest Neighbors)**
```python
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(
    n_neighbors=5,
    weights='distance',
    n_jobs=-1
)
```

**Avantages** : Simple, pas de training
**InconvÃ©nients** : Lent en prÃ©diction, sensible au bruit

### Training

```bash
python train.py ./leaves/images/ --epochs 10 --model_type svm
```

**Sortie** :
```
Scanning dataset...
Found 8 classes, 3424 images

Splitting dataset...
Train: 2739 images
Valid: 685 images

Augmenting train set...
Created 8217 augmented images

Extracting features...
Train features: (11956, 824)
Valid features: (685, 824)

Normalizing features...
StandardScaler fitted

Training SVM...
Training completed in 45.2s

Evaluating...
Train accuracy: 98.5%
Valid accuracy: 92.3% âœ…
Valid count: 685 âœ…

Saving model...
Model saved to artifacts/model/

Creating learnings.zip...
âœ… Training completed!
```

### PrÃ©diction

```bash
python predict.py learnings.zip "./leaves/images/Apple_Black_rot/image (1).JPG"
```

**Sortie** :
```
Loading model...
Extracting features...
Predicting...

Predicted class: Apple_Black_rot
Confidence: 95.7%

Top 3 predictions:
1. Apple_Black_rot: 95.7%
2. Apple_scab: 3.2%
3. Grape_Black_rot: 1.1%
```

---

<a id="module-leaffliction"></a>
## 8. Module leaffliction/

### Structure

```
leaffliction/
â”œâ”€â”€ cli.py                   # âœ… Parsers argparse
â”œâ”€â”€ utils.py                 # âœ… PathManager, Hasher, ZipPackager
â”œâ”€â”€ plotting.py              # âœ… DistributionPlotter, GridPlotter
â”œâ”€â”€ dataset.py               # DatasetScanner, DatasetSplitter
â”œâ”€â”€ augmentations.py         # AugmentationEngine (images physiques)
â”œâ”€â”€ transformations.py       # TransformationEngine + FeatureExtractor â­
â”œâ”€â”€ model.py                 # MLModelFactory, MLModelBundle
â”œâ”€â”€ train_pipeline.py        # MLTrainer
â””â”€â”€ predict_pipeline.py      # MLPredictor
```

### Fichiers ClÃ©s

#### **transformations.py** â­ **CRUCIAL**

**FeatureExtractor** : Classe centrale pour ML traditionnel

```python
class FeatureExtractor:
    def extract_features(self, img_path: Path) -> np.ndarray:
        """
        Extrait ~800-1000 features numÃ©riques depuis une image
        
        Returns:
            np.ndarray de shape (n_features,)
        """
        # 1. Charger image
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        features = []
        
        # 2. Histogrammes RGB
        for channel in range(3):
            hist, _ = np.histogram(img[:,:,channel], bins=256)
            hist = hist / hist.sum()
            features.extend(hist)
        
        # 3. Statistiques RGB
        for channel in range(3):
            features.append(img[:,:,channel].mean())
            features.append(img[:,:,channel].std())
            features.append(img[:,:,channel].min())
            features.append(img[:,:,channel].max())
        
        # 4. Appliquer transformations et extraire stats
        for tf in self.transformations:
            transformed = tf.apply(img)
            features.append(transformed.mean())
            features.append(transformed.std())
            features.append(transformed.min())
            features.append(transformed.max())
        
        return np.array(features, dtype=np.float32)
```

#### **model.py**

**MLModelFactory** : Construit des modÃ¨les sklearn

```python
class MLModelFactory:
    def build(self, cfg: ModelConfig, model_type: str = "svm"):
        if model_type == "svm":
            return SVC(kernel='rbf', C=1.0, probability=True)
        elif model_type == "random_forest":
            return RandomForestClassifier(n_estimators=100)
        elif model_type == "knn":
            return KNeighborsClassifier(n_neighbors=5)
```

**MLModelBundle** : Sauvegarde/charge le modÃ¨le

```python
class MLModelBundle:
    def save(self, out_dir: Path):
        """
        Sauvegarde:
        - model.pkl (modÃ¨le sklearn)
        - scaler.pkl (StandardScaler)
        - labels.json
        - config.json
        """
        joblib.dump(self.model, out_dir / "model.pkl")
        joblib.dump(self.scaler, out_dir / "scaler.pkl")
        # ... labels et config en JSON
```

#### **train_pipeline.py**

**MLTrainer** : Orchestrateur complet

```python
class MLTrainer:
    def train(self, dataset_dir, out_dir, cfg) -> Metrics:
        # 1. Scanner
        index = self.dataset_scanner.scan(dataset_dir)
        
        # 2. Split
        train_items, valid_items = self.dataset_splitter.split(...)
        
        # 3. Augmenter (optionnel)
        if cfg.augment_train:
            train_items = aug_engine.augment_dataset(...)
        
        # 4. Extraire features
        X_train, y_train = feature_extractor.extract_batch(train_items)
        X_valid, y_valid = feature_extractor.extract_batch(valid_items)
        
        # 5. Normaliser
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_valid_scaled = scaler.transform(X_valid)
        
        # 6. EntraÃ®ner
        model = self.model_factory.build(cfg, model_type="svm")
        model.fit(X_train_scaled, y_train)
        
        # 7. Ã‰valuer
        valid_acc = model.score(X_valid_scaled, y_valid)
        
        # 8. Sauvegarder
        bundle = MLModelBundle(model, scaler, labels, ...)
        bundle.save(out_dir / "model")
        
        return Metrics(...)
```

---

<a id="pipeline-ml-traditionnel-dÃ©taillÃ©"></a>
## 9. Pipeline ML Traditionnel dÃ©taillÃ©

### SchÃ©ma Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING (train.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Dataset brut (leaves/images/)
   â†“
2. DatasetScanner.scan()
   â†’ DatasetIndex (class_names, items, counts)
   â†“
3. DatasetSplitter.split() (stratifiÃ©)
   â†’ train_items (80%), valid_items (20%)
   â†“
4. AugmentationEngine.augment_dataset() [OPTIONNEL]
   â†’ CrÃ©e images physiques sur disque
   â†’ train_items Ã©tendu (originales + augmentÃ©es)
   â†“
5. FeatureExtractor.extract_batch(train_items)
   â†’ X_train (n_train, 824), y_train (n_train,)
   â†“
6. FeatureExtractor.extract_batch(valid_items)
   â†’ X_valid (n_valid, 824), y_valid (n_valid,)
   â†“
7. StandardScaler
   â†’ fit_transform(X_train) â†’ X_train_scaled
   â†’ transform(X_valid) â†’ X_valid_scaled
   â†“
8. MLModelFactory.build(model_type="svm")
   â†’ model sklearn
   â†“
9. model.fit(X_train_scaled, y_train)
   â†’ EntraÃ®nement
   â†“
10. model.score(X_valid_scaled, y_valid)
    â†’ Accuracy validation > 90% âœ…
    â†“
11. MLModelBundle.save()
    â†’ model.pkl, scaler.pkl, labels.json
    â†“
12. TrainingPackager.build_zip()
    â†’ learnings.zip


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PRÃ‰DICTION (predict.py)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Image test
   â†“
2. MLModelBundle.load_from_zip(learnings.zip)
   â†’ model, scaler, labels, feature_extractor
   â†“
3. FeatureExtractor.extract_features(image_path)
   â†’ features (824,)
   â†“
4. scaler.transform(features)
   â†’ features_scaled (824,)
   â†“
5. model.predict(features_scaled)
   â†’ class_id
   â†“
6. model.predict_proba(features_scaled)
   â†’ probabilitÃ©s
   â†“
7. LabelEncoder.decode(class_id)
   â†’ nom de la classe
   â†“
8. Affichage rÃ©sultat
```

---

<a id="mathÃ©matiques-et-formules"></a>
## 10. MathÃ©matiques et formules

### ğŸ”¹ StandardScaler (Normalisation)

**Formule** :
```
x_scaled = (x - mean) / std
```

**Pourquoi** : Met toutes les features sur la mÃªme Ã©chelle (mean=0, std=1)

**Exemple** :
```
Feature 1: [100, 200, 300] â†’ mean=200, std=81.6
Feature 2: [0.1, 0.2, 0.3] â†’ mean=0.2, std=0.08

AprÃ¨s normalisation:
Feature 1: [-1.22, 0, 1.22]
Feature 2: [-1.22, 0, 1.22]

â†’ MÃªme Ã©chelle !
```

### ğŸ”¹ SVM (Support Vector Machine)

**Objectif** : Trouver l'hyperplan qui sÃ©pare au mieux les classes

**Formule du kernel RBF** :
```
K(x, x') = exp(-Î³ ||x - x'||Â²)
```

OÃ¹ :
- Î³ = gamma (contrÃ´le la "portÃ©e" du kernel)
- ||x - x'|| = distance euclidienne

**DÃ©cision** :
```
f(x) = sign(Î£ Î±áµ¢ yáµ¢ K(xáµ¢, x) + b)
```

### ğŸ”¹ Random Forest

**Principe** : Ensemble d'arbres de dÃ©cision

**PrÃ©diction** :
```
Å· = mode{treeâ‚(x), treeâ‚‚(x), ..., tree_n(x)}
```

**ProbabilitÃ©** :
```
P(classe_k | x) = (nombre d'arbres prÃ©disant k) / n_arbres
```

### ğŸ”¹ KNN (K-Nearest Neighbors)

**Principe** : Voter parmi les K voisins les plus proches

**Distance euclidienne** :
```
d(x, x') = âˆš(Î£áµ¢ (xáµ¢ - x'áµ¢)Â²)
```

**PrÃ©diction** :
```
Å· = mode{yâ‚, yâ‚‚, ..., y_k}
```

OÃ¹ yâ‚, ..., y_k sont les labels des K voisins les plus proches.

### ğŸ”¹ Accuracy

```
Accuracy = (Nombre de prÃ©dictions correctes) / (Nombre total)
```

**Contrainte du sujet** : Accuracy > 90%

### ğŸ”¹ Histogramme

**Formule** :
```
hist[i] = nombre de pixels avec valeur dans [i, i+1)
hist_normalized[i] = hist[i] / Î£ hist[j]
```

**Exemple** :
```
Image 100Ã—100 = 10000 pixels
Valeurs entre 0-255

hist[120] = 150  â†’ 150 pixels ont valeur ~120
hist_normalized[120] = 150/10000 = 0.015 = 1.5%
```

---

<a id="contraintes-du-sujet"></a>
## 11. Contraintes du sujet

### âœ… Contraintes Obligatoires

| Contrainte | Valeur | VÃ©rification |
|-----------|--------|--------------|
| **Validation accuracy** | > 90% | `RequirementsGate.assert_ok()` |
| **Validation set size** | â‰¥ 100 images | `metrics.valid_count >= 100` |
| **Augmentations** | 6 types | `AugmentationEngine.default_six()` |
| **Transformations** | 6 types | `TransformationEngine.default_six()` |
| **Dataset dans repo** | âŒ INTERDIT | Seulement `signature.txt` |

### ğŸ“¦ Structure du learnings.zip

```
learnings.zip/
â”œâ”€â”€ model.pkl              # ModÃ¨le sklearn (SVM/RF/KNN)
â”œâ”€â”€ scaler.pkl             # StandardScaler
â”œâ”€â”€ labels.json            # {"Apple_Black_rot": 0, ...}
â”œâ”€â”€ config.json            # {"num_classes": 8, ...}
â””â”€â”€ feature_config.json    # Config des features
```

---

<a id="gÃ©nÃ©ration-de-signaturetxt"></a>
## 12. GÃ©nÃ©ration de signature.txt

### Commandes

```bash
# Linux/macOS
sha1sum learnings.zip > signature.txt

# Windows
certUtil -hashfile learnings.zip sha1 > signature.txt
```

### Automatisation

```python
from leaffliction.utils import Hasher

hasher = Hasher()
sha1_hash = hasher.ft_sha1_file(Path("learnings.zip"))

with open("signature.txt", "w") as f:
    f.write(sha1_hash + "\n")
```

### âš ï¸ IMPORTANT

- âŒ Ne JAMAIS modifier `learnings.zip` aprÃ¨s avoir gÃ©nÃ©rÃ© `signature.txt`
- âŒ Ne JAMAIS commit `learnings.zip` dans git
- âœ… Seulement commit `signature.txt`

---

<a id="checklist-finale"></a>
## 13. Checklist finale

### ğŸ“‹ Code

- [ ] `Distribution.py` fonctionne
- [ ] `Augmentation.py` affiche et sauvegarde 6 augmentations
- [ ] `Transformation.py` affiche 6 transformations
- [ ] `train.py` entraÃ®ne le modÃ¨le ML
- [ ] `predict.py` prÃ©dit correctement
- [ ] SÃ©paration logique/entrypoint respectÃ©e

### ğŸ“Š Dataset

- [ ] Dataset Ã©quilibrÃ© (ou augmentÃ©)
- [ ] Split stratifiÃ©
- [ ] Validation â‰¥ 100 images
- [ ] Pas de data leakage

### ğŸ“ ModÃ¨le

- [ ] Accuracy validation > 90%
- [ ] ModÃ¨le reproductible (seed fixÃ©)
- [ ] Features bien extraites
- [ ] Normalisation correcte

### ğŸ“¦ Packaging

- [ ] `learnings.zip` contient tout
- [ ] `signature.txt` correct
- [ ] SHA1 vÃ©rifiÃ©
- [ ] Pas de fichiers inutiles

---

<a id="conseils-pour-la-soutenance"></a>
## 14. Conseils pour la soutenance

### ğŸ¯ Points Forts de l'Approche ML

**Ã€ mettre en avant** :
1. **SimplicitÃ©** : "J'ai choisi ML traditionnel car plus simple Ã  comprendre et expliquer"
2. **RapiditÃ©** : "Training en 2 minutes vs 2 heures pour CNN"
3. **InterprÃ©tabilitÃ©** : "Je peux montrer exactement quelles features sont importantes"
4. **EfficacitÃ©** : "Pas besoin de GPU, fonctionne sur n'importe quel ordinateur"

### ğŸ“Š DÃ©monstration

**Script de dÃ©mo** :
```bash
# 1. Distribution
python Distribution.py ./leaves/images/
# â†’ Montrer le dÃ©sÃ©quilibre

# 2. Augmentation
python Augmentation.py "./leaves/images/Apple_healthy/image (1).JPG"
# â†’ Montrer les 6 augmentations

# 3. Transformation
python Transformation.py "./leaves/images/Apple_healthy/image (1).JPG"
# â†’ Montrer les 6 transformations

# 4. Training
python train.py ./leaves/images/ --model_type svm
# â†’ Montrer les logs, accuracy > 90%

# 5. Prediction
python predict.py learnings.zip "./test_image.jpg"
# â†’ Montrer la prÃ©diction
```

### ğŸ—£ï¸ Questions Probables

**Q: Pourquoi ML traditionnel et pas CNN ?**
R: "ML traditionnel est plus
